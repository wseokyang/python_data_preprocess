{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba8e0db0",
   "metadata": {},
   "source": [
    "# 변수 형식 처리 및 파생변수 생성\n",
    "\n",
    "### 주요 내용\n",
    "\n",
    "1. 변수 수정, 추가 및 제거\n",
    "2. 형식 변환\n",
    "3. 결측값 처리 및 파생변수 생성\n",
    "\n",
    "<br>\n",
    "\n",
    "### 목표 \n",
    "1. 분석 목적에 맞게 변수를 수정하고 파생 변수를 추가할 수 있다.\n",
    "2. 날짜 등 변수 형식을 활용할 수 있다.\n",
    "3. 결측값을 적절한 값으로 대체하는 방법을 확인한다.\n",
    "\n",
    "\n",
    "<br>\n",
    "<hr>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742e02b1",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1. 변수(열)의 수정, 추가, 제거\n",
    "\n",
    "**pandas**의 기본 기능과 메서드를 활용하여 변수를 추가 하거나 수정, 업데이트하거나 제거할 수 있습니다.  \n",
    "변수를 선택하듯 **=**을 활용해서 변수를 추가하거나 업데이트 할 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50aa7e9a",
   "metadata": {},
   "source": [
    "### 1.1. 변수 수정 및 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828f2202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 불러오기\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# 예제 만들기 : 딕셔너리를 활용한 DataFrame 생성\n",
    "df_own = pd.DataFrame({'FIRST' : ['A', 'B', 'C', 'D'],\n",
    "                       'SECOND': [7,6,5,8], \n",
    "                       'THIRD' : pd.date_range('2023-01-01', periods=4, freq='W-SAT')})\n",
    "df_own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754b6273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수이름을 활용한 변수선택\n",
    "df_own['SECOND']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f6e5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =을 활용한 추가\n",
    "df_own['FOURTH'] = 0\n",
    "df_own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a269ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =을 활용한 업데이트\n",
    "df_own['FOURTH'] = df_own['SECOND'] + 1\n",
    "df_own"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d06ed5c",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 1.2. 객체 메서드와 Series 메서드의 비교\n",
    "\n",
    "특히 날짜시간 변수의 경우 월, 일, 요일, 시간 등 다양한 요소를 추출해서 변수로 추가할 수 있는데, 객체 자체의 메서드를 활용하거나 **pandas**의 함수를 활용할 수 있습니다.  \n",
    "\n",
    "Python은 개발언어로 객체의 형식에 매우 엄격합니다. 개별 날짜에 적용할 수 있는 메서드는 **pandas**의 **Series**에는 적용할 수 없기 때문에 *apply()*등을 활용해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a39ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# []와 for를 활용한 파생변수 생성\n",
    "df_own.loc[0, 'THIRD'].weekday()\n",
    "    ## 하나의 값에 대해서는 메서드 활용가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4076b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series에 대해서는 Series의 메서드만 활용 가능\n",
    "# df_own['THIRD'].weekday()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8e4845",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_own['THIRD'].apply(lambda x: x.weekday())\n",
    "df_own"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cac9c3c",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "pandas의 *dt.weekday*를 활용하면 훨씬 손쉽게 파생변수를 만들수 있습니다.\n",
    " * 참고: [dt.weekday](https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.weekday.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86c3840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas의 dt.weekday 활용\n",
    "df_own['THIRD'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ef740d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_own['WEEKDAY'] = df_own['THIRD'].dt.weekday"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dd17c7",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 1.3. 조건을 활용한 값 생성 및 변수 제거\n",
    "\n",
    "조건을 활용해 일부 관측치를 선택하듯이, 조건을 설정하고 변수를 추가하거나 업데이트 하는 것도 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06678bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일부 관측치만 값 생성\n",
    "df_own.loc[df_own['FIRST'].isin(['A','B']), 'OPTIONAL'] = 1\n",
    "df_own\n",
    "    ## NaN := 결측값(missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885f988b",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "*drop()*은 관측치와 변수를 제거할 수 있는데 **index**와 **columns**를 활용합니다. `axis=`옵션에 따라 `axis=0`이면 관측치를 제거하거 `axis=1`이면 변수를 제거합니다.  \n",
    "\n",
    "`columns=`이라는 옵션을 명시해서 변수를 제거하는 것이 가장 명확하고 실수를 줄일 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3907eb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop()을 활용한 관측치/변수 제거\n",
    "df_own.drop('FOURTH', axis=1)\n",
    "    # axis = 0 : 관측치\n",
    "    # axis = 1 : 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d153005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop()을 활용한 관측치/변수 제거(columns 활용)\n",
    "df_own.drop(columns=['FOURTH'])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c919fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop( ) 실행 후 원본 데이터는 변함이 없음\n",
    "df_own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d27e897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본 데이터의 업데이트\n",
    "df_own = df_own.drop(columns=['FOURTH'])\n",
    "df_own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7dc3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리스트를 활용한 복수 인덱스 제거\n",
    "df_own = df_own.drop([0,3], axis=0)\n",
    "df_own"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ea60e3",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 1.4. 결측값 대체 예제\n",
    "\n",
    "**DataFrame**에서 결측값은 *NaN*으로 표시됩니다. 특정한 변수를 기준으로 각 관측치의 결측여부를 따지는 함수는 *isnull()*이고 기존의 방법을 조합해서 아래처럼 간단하게 결측값을 적절하게 대체할 수 있습니다.  \n",
    "결측값 대체는 아래에서 다시 한번 더 다루겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f911c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_own.loc[df_own['OPTIONAL'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c50ec26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_own.loc[df_own['OPTIONAL'].isnull(), 'OPTIONAL']  = 0.0\n",
    "df_own"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6285ad",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 1.5. 변수 이름 변경\n",
    "\n",
    "변수이름을 바꾸고 싶을 때는 **DataFrame**의 메서드 *rename()*을 활용할 수 있습니다.  \n",
    "이때 `columns=` 옵션을 활용하고 딕셔너리 형식으로 기존변수이름과 새변수이름을 콜론으로 연결하면 됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a42b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename() 활용 변수 이름 바꾸기 \n",
    "df_own.rename(columns = {'FIRST':'var1', 'SECOND':'var2'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7ce7c3",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### [실습] df_sp를 활용\n",
    "\n",
    "1. 'math score', 'reading score', 'writing score'를 합한 변수 'total' 추가\n",
    "2. 1의 'total'이 270이상인 학생들만 'EX'라는 값을 갖는 'grade' 변수 추가\n",
    "3. 'math score'가 40보다 작은지 비교 연산하고 True/False 값을 갖는 결과 Series를 변수 'math grp'로 추가하기\n",
    "4. 'reading score'가 40보다 작은지 비교 연산하고 결과를 'reading grp'로 추가하기\n",
    "5. 'writing score'가 40보다 작은지 비교 연산하고 결과를 'writing grp'로 추가하기\n",
    "6. 3., 4., 5.를 활용해서 세 점수 중 하나라도 40점 미만은 학생은 'grade'를 'FAIL'로 수정하기\n",
    "7. 3., 4., 5.의 세 변수를 제거하기\n",
    "8. 'grade'의 이름을 'class'로 바꾸기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f0c085",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp = pd.read_csv('data/StudentsPerformance.csv')\n",
    "df_sp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ad4617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c0b14d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cfd1d9d0",
   "metadata": {},
   "source": [
    "#### [참고] DataFrame의 sum(), any()등 활용 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ba2fdc",
   "metadata": {},
   "source": [
    "<br>\n",
    "<hr>\n",
    "<br>\n",
    "\n",
    "## 2. 결측값 처리\n",
    "\n",
    "결측값은 다양한 이유로 생길 수 있습니다.  \n",
    "- 애초에 값이 없는 경우\n",
    "- 값이 있으나 사람 실수로 누락한 경우\n",
    "- 센서, 통신망 등의 오류로 값이 들어오지 않은 경우\n",
    "\n",
    "먼저 결측값 존재 여부 확인하고, 대체를 할 지 그대로 둘 지를 결정해야 합니다. 대체를 한다면 어떤 값으로 채울지도 고민해야합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd8155b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 데이터 불러오기\n",
    "df_na = pd.read_csv('./data/data_dupna.csv')\n",
    "df_na\n",
    "    # NaN : 결측"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c83138",
   "metadata": {},
   "source": [
    "<br>\n",
    "아래의 명령어를 활용하면 전체 데이터에서 결측값이 있는 관측치나 변수를 확인할 수 있습니다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e06d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하나라도 결측값이 있는 변수 확인\n",
    "df_na.isnull().any(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd77c305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하나라도 결측값이 있는 관측치 확인\n",
    "df_na[df_na.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451e0375",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### [참고]\n",
    "집계 함수의 경우 결측값이 있는 경우 결측값을 제외하고 계산하도록 기본값이 설정되어 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee15f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_na['amount'].mean(), df_na['amount'].mean(skipna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ef8b09",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 2.1. 결측값 포함 관측치 제거\n",
    "\n",
    "결측값이 있는 관측치에 대응하는 가장 간단한 방법은 결측치를 포함한 변수나 관측치를 제거하는 방법입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7619168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하나라도 결측값이 있는 관측치 제거\n",
    "df_na.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c525f03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정 변수 기준 결측값이 있는 관측치 제거\n",
    "df_na.dropna(subset=['info1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a835c27",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 2.2. 결측값 대체\n",
    "\n",
    "다음으로 결측값을 적절한 값으로 대체할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1a7422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 결측값을 일괄 대체\n",
    "df_na.fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968c1d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수별 결측값 대체 지정\n",
    "df_na.fillna(value={'info1':0, 'info2':'NA'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84147b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 앞쪽의 결측이 아닌 값으로 대체\n",
    "    ## 센서 등의 값 누락에 활용\n",
    "df_na.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4da6662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이후 값중 결측이 아닌 값으로 대체\n",
    "    ## groupby()를 활용하여 id 등 범위 내 대체\n",
    "df_na.groupby('id').fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd838862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정한 변수만 결측값 대체\n",
    "    ## groupby()와 fillna()를 활용할 경우 그룹변수가 사라짐\n",
    "    ## 특정 변수만 선택해서 결측값 대체하고 업데이트\n",
    "df_na['info2'] = df_na.groupby('id')['info2'].fillna(method='ffill')    \n",
    "df_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bb2c6a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30668a29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f8455ab",
   "metadata": {},
   "source": [
    "<br>\n",
    "<hr>\n",
    "<br>\n",
    "\n",
    "## 3. 변수 형식 변환 및 파생변수 생성\n",
    "\n",
    "대부분의 분석 과정에서 변수 형식은 크게 고려하지 않아도 됩니다. *read_csv()* 로 데이터를 불러오면 적당한 형식으로 지정되는데, 가끔 형식을 직접 바꿔야할 때가 있습니다.  \n",
    "\n",
    "파생 변수 역시 비슷합니다. 데이터에 포함된 변수만으로 데이터 활용이나 분석이 가능한 경우가 많지만, 때에 따라 기존 변수를 활용해서 새로운 변수를 추가해서 분석에 활용해야하는 경우가 있습니다. 날짜에서 요일 등을 추출하는 것이 대표적인 예제입니다.  \n",
    "\n",
    "\n",
    "### 3.1. 변수 형식의 확인/변환\n",
    "**DataFrame**에서 주로 활용하는 변수 형식은 다음과 같습니다.\n",
    "\n",
    "+ float: 실수(소수점을 포함한 숫자)\n",
    "+ int: 정수(integer)\n",
    "+ datetime: 날짜시간\n",
    "+ bool: 불/불린(True 혹은 False)\n",
    "+ category: 범주형\n",
    "+ object: 문자형(string) 혹은 그 외\n",
    "\n",
    "*.dtypes* 를 활용하면 변수 형식을 확인할 수 있습니다. 그리고 *.astype()* 을 활용해서 변수 형식을 변환할 수 있습니다. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da530ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "df_ins = pd.read_csv('data/insurance.csv')\n",
    "df_ins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ca72ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수 형식 확인\n",
    "df_ins.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2787973f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# children을 float으로 변환\n",
    "df_ins['children'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e1048a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# children을 object로 변환\n",
    "df_ins['children'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17846dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 변수의 형식 업데이트\n",
    "df_ins['children'] = df_ins['children'].astype('float')\n",
    "df_ins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b7795a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 복수 변수의 형식 일괄 업데이트\n",
    "category_vars = ['sex', 'smoker', 'region']\n",
    "df_ins[category_vars] = df_ins[category_vars].astype('category')\n",
    "df_ins.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b48d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select_dtypes()의 활용\n",
    "df_ins.select_dtypes('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea8890f",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### [실습] df_pr의 활용\n",
    "\n",
    "1. Pulse2(뛴 후)와 Pulse1(뛰기 전)의 차이를 계산하고 'Diff'로 변수 추가하기\n",
    "2. .dtypes로 형식 확인하고 .nunique()로 중복값 제거한 값 개수 확인하기\n",
    "3. 범주형 형식이 적당한 변수 목록 만들기\n",
    "4. 3.의 변수들을 astype()으로 category 형식으로 변환하고 업데이트 하기\n",
    "5. Ran, Smokes, Alcohol별 1.의 Diff의 평균 계산하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b37472",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pr = pd.read_csv('data/PulseRates.csv')\n",
    "df_pr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0e665a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e58420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40d3819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921b40ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8886112",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 3.2. 수치형 변수의 구간화\n",
    "\n",
    "수치형 변수는 그대로 활용하기 보다는 구간화하는 경우가 많습니다. 상황에 따라 적절한 방법을 선택하면 되는데, *cut()* 이나 *qcut()* 함수를 주로 활용합니다.  \n",
    "\n",
    "+ *cut()*: 등간격 혹은 주어진 구간 경계로 구간화\n",
    "+ *qcut()*: 등비율로 구간화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37bce15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 연령대 변수 생성\n",
    "    ## //: 몫 계산\n",
    "    ## %: 나머지 계산\n",
    "df_ins['age_grp'] = (df_ins['age'] // 10).astype('category')\n",
    "df_ins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22ee624",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ins['age_grp'] = (df_ins['age'] // 10).apply(lambda x: str(x)+'0대')\n",
    "df_ins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9450ca",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "*cut()*을 활용해서 등간격으로 구간화할 수 있고, `bins=` 옵션에 적절한 구간값을 직접 넣을 수도 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aedfb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 등간격으로 구간화하기\n",
    "pd.cut(df_ins['charges'], bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02041da",
   "metadata": {},
   "outputs": [],
   "source": [
    "charges_breaks = [0, 5000, 10000, 20000, 100000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddd906d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.cut(df_ins['charges'], bins=charges_breaks, right=False, labels=['1','2','3','4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd9af61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut()을 활용한 10등급화\n",
    "df_ins['charges_grp'] = pd.cut(df_ins['charges'], bins=10, labels=range(10))\n",
    "df_ins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1973c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 등구간의 관측치 불균형 문제\n",
    "df_ins['charges_grp'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b72b845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qcut()을 활용한 등비율 구간화\n",
    "df_ins['charges_grp2'] = pd.qcut(df_ins['charges'], q=10, labels=range(1, 11))\n",
    "df_ins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a44be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ins['charges_grp2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2578b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4d43cde",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### [실습] 데이터 df_sp 활용\n",
    "\n",
    "1. cut()으로 'reading score'를 20점 단위로 5개 그룹 변수 추가 \n",
    "2. cut()으로 'reading score'를 등간격(구간 길이가 동일)으로 5개 그룹 변수 추가\n",
    "3. qcut()으로 'readiong score'를 등비율로 5 등급화\n",
    "4. pivot_table()을 활용해서 'parental level of education'과 3.의 그룹 변수로 'math score'의 평균 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adf57ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affd0b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0728640",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aa35b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976112df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20347139",
   "metadata": {},
   "source": [
    "### 3.3. 그룹 내 순위, 이동, 누적 변수 생성\n",
    "\n",
    "데이터 분석 과정에서 그룹별로 순위를 매기거나, 직전 값과 비교를 통해서 변화량 등을 확인하기도 합니다. 뿐만 아니라 이동 평균이나 누적 최댓값 등을 계산하기도 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdf5c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "df_dup = pd.read_csv('data/data_dupna.csv')\n",
    "df_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3ab8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 순위 생성(동점일 경우 평균 등수)\n",
    "df_dup['amount'].rank(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2af0240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 순위 생성(동점일 경우 index 순)\n",
    "df_dup['date'].rank(ascending=True, method='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d037506",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 사용자별 순위 파생변수 추가\n",
    "df_dup['seq'] = df_dup.groupby('id')['date'].rank(method='min',ascending=False)\n",
    "df_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acccfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank 활용 최종건 선택\n",
    "df_dup[df_dup['seq']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0023a403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 정렬 및 날짜 형식 변환\n",
    "df_dup = df_dup.sort_values(['id','date']).reset_index(drop=True)\n",
    "df_dup['date'] = df_dup['date'].astype('datetime64')\n",
    "df_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2199acbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그룹별 이동 값 변수 추가\n",
    "df_dup['date_prev'] = df_dup.groupby('id')['date'].shift()\n",
    "df_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25325e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시차의 계산\n",
    "df_dup['date_diff'] = df_dup['date'] - df_dup['date_prev']\n",
    "df_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5eee81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그룹별 누적합 계산\n",
    "df_dup['cum_amount'] = df_dup.groupby('id')['amount'].cumsum()\n",
    "df_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49910e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rolling() 활용 그룹별 이동 평균 계산\n",
    "df_dup['ma_amount'] = df_dup.groupby('id').rolling(2)['amount'].mean().reset_index(drop=True)\n",
    "df_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c45426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53a3766",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0673fe1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b00ee6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7edd620b",
   "metadata": {},
   "source": [
    "## 4. 날짜시간 변수 활용\n",
    "\n",
    "날짜시간 변수에서 요소를 추출할 수 있고, 날짜시간별로 집계된 데이터로 시각화할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddb5eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a851bcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글 폰트 설정 (Windows)\n",
    "from matplotlib import font_manager, rc\n",
    "f_path = \"c:/Windows/Fonts/malgun.ttf\"\n",
    "font_name = font_manager.FontProperties(fname=f_path).get_name()\n",
    "rc('font', family=font_name)\n",
    "plt.rcParams['axes.unicode_minus'] = False  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff9c65b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_subway = pd.read_csv('data/서울교통공사_역별일별승하차인원정보_20220731.csv')\n",
    "df_subway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3461369b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_datetime()을 활용한 형식 변환\n",
    "df_subway['호선'] = df_subway['호선'].astype('category')\n",
    "df_subway['날짜'] = pd.to_datetime(df_subway['날짜'])\n",
    "df_subway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2adeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요일 변수 생성\n",
    "df_subway['요일'] = df_subway['날짜'].dt.weekday\n",
    "df_subway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d929b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 월 변수 생성\n",
    "df_subway['월'] = df_subway['날짜'].dt.month\n",
    "df_subway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ed8c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 날짜별 집계값의 생성\n",
    "agg = df_subway.groupby(['날짜','호선'], as_index=False)['이용객수'].sum()\n",
    "agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4463267c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 시계열 데이터의 시각화 \n",
    "sns.lineplot(data=agg, \n",
    "             x='날짜',\n",
    "             y='이용객수',\n",
    "             hue='호선')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86515b80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b07bac0",
   "metadata": {},
   "source": [
    "#### [실습] df_accident를 활용하여 7, 8월 새벽 1~5시 사고 건수 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683290a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_accident = pd.read_csv('data/도로교통공단_사망 교통사고 정보_20211231_utf8.csv')\n",
    "df_accident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e98959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ddc2689",
   "metadata": {},
   "source": [
    "#### End of script"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
